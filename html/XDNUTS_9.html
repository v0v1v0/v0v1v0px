<div class="container">

<table style="width: 100%;"><tr>
<td>xdnuts</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Discontinuous Hamiltonian Monte Carlo using both manual and automatic termination criteria.</h2>

<h3>Description</h3>

<p>The function allows generating multiple Markov Chains for sampling from both continuous and discontinuous
posterior distributions using a variety of algorithms. Classic Hamiltonian Monte Carlo (Duane et al. 1987), 
NUTS (Hoffman et al. 2014), and XHMC (Betancourt 2016) are embedded into the framework
described in (Nishimura et al. 2020), which allows dealing with such posteriors.
Furthermore, for each method, it is possible to recycle samples from the trajectories using
the method proposed by (Nishimura and Dunson 2020).
This is used to improve the estimate of the Mass Matrix during the warm-up phase
without requiring a relevant additional computational cost.
</p>


<h3>Usage</h3>

<pre><code class="language-R">xdnuts(
  theta0,
  nlp,
  args,
  k,
  N = 1000,
  K = 3,
  method = "NUTS",
  tau = NULL,
  L = NULL,
  thin = 1,
  control = set_parameters(),
  parallel = FALSE,
  verbose = FALSE,
  hide = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>theta0</code></td>
<td>
<p>a list containing the starting values for each chain. These starting values are vectors of length-<code class="reqn">d</code>. 
The last <code class="reqn">k \in [0,d]</code> elements refer to parameters which determine a discontinuity in the posterior distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlp</code></td>
<td>
<p>a function which evaluates the negative log posterior and its gradient with respect to 
parameters that do not induce any discontinuity in the posterior distribution (more generally, the first <code class="reqn">d-k</code> parameters).
This function must take 3 arguments:
</p>

<dl>
<dt>par</dt>
<dd>
<p>a vector of length-<code class="reqn">d</code> containing the parameter values.</p>
</dd>
<dt>args</dt>
<dd>
<p>a list object that contains the necessary arguments, namely data and hyperparameters.</p>
</dd>
<dt>eval_nlp</dt>
<dd>
<p>a boolean value, <code>TRUE</code> to evaluate only the negative log posterior of the models, 
<code>FALSE</code> to evaluate its gradient with respect to the continuous components of the posterior.</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>args</code></td>
<td>
<p>a list containing the inputs for the negative posterior function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>an integer value that states the number of parameters that determines a discontinuity in the posterior distribution.
Actually, since the algorithm proposed in (Nishimura et al. 2020) also works for the full continuous case,
<code>k</code> is the number of parameters specified by the user for which this algorithm is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>the number of draws from the posterior distribution, after warm-up, for each chain. Default value is <code>1000</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>the number of recycled samples per iteration used by default during the warm-up phase.
Default value is <code>3</code>. To recycle in the sampling phase too, specify <code>recycle_only_init = FALSE</code>
in the <code>control</code> argument above.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>a character value which defines the type of algorithm to exploit:</p>

<dl>
<dt><code>"NUTS"</code></dt>
<dd>
<p>applies the No U-Turn Sampler of (Hoffman et al. 2014).</p>
</dd>
<dt><code>"XHMC"</code></dt>
<dd>
<p>applies the Exhaustion Hamiltonian Monte Carlo of (Betancourt 2016).</p>
</dd>
<dt><code>"HMC"</code></dt>
<dd>
<p>applies one of the classic version of Hamiltonian Monte Carlo algorithm,
in particular the one described in (Betancourt 2017), which samples from the trajectory instead of always returning the last value.</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tau</code></td>
<td>
<p>the threshold for the virial termination criterion (Betancourt 2016).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>L</code></td>
<td>
<p>the desired length of the trajectory of classic Hamiltonian Monte Carlo algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thin</code></td>
<td>
<p>the number of necessary and discarded samples to obtain a final iteration of one chain.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>an object of class <code>control_xdnuts</code>, output of the function set_parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parallel</code></td>
<td>
<p>a boolean value specifying whether the chains must be run in parallel. Default value is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>a boolean value for printing all the information regarding the sampling process.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hide</code></td>
<td>
<p>a boolean value that omits the printing to the console if set to <code>TRUE</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a list of class <code>XDNUTS</code> containing </p>

<dl>
<dt>chains</dt>
<dd>
<p>a list of the same length of <code>theta0</code>, each element containing the output from the function main_function.</p>
</dd>
<dt>d</dt>
<dd>
<p>the dimension of the parameter space.</p>
</dd>
<dt>k</dt>
<dd>
<p>the number of parameters that lead to a discontinuous posterior distribution. 
Or, more generally, for which the algorithm of (Nishimura et al. 2020) is exploited.</p>
</dd>
<dt>K</dt>
<dd>
<p>the number of recycled samples for each iteration during the sampling phase.</p>
</dd>
<dt>N</dt>
<dd>
<p>the number of posterior draws for each chain.</p>
</dd>
<dt>method</dt>
<dd>
<p>the MCMC method used. This could be either "NUTS", "XHMC", or "HMC".</p>
</dd>
<dt>tau</dt>
<dd>
<p>the threshold for the virial termination criterion (Betancourt 2016). 
Only if <code>method = "XHMC"</code> this value is different from zero.</p>
</dd>
<dt>L</dt>
<dd>
<p>the desired length of the trajectory of classic Hamiltonian Monte Carlo algorithm specified by the user.
This argument is necessary if <code>method = "HMC"</code>.</p>
</dd>
<dt>thin</dt>
<dd>
<p>the number of discarded samples for every final iteration, specified by the user.</p>
</dd>
<dt>control</dt>
<dd>
<p>an object of class <code>control_xdnuts</code>, output of the function set_parameters with arguments specified by the user.</p>
</dd>
<dt>verbose</dt>
<dd>
<p>the boolean value specified by the user regarding the printing of the sampling process information.</p>
</dd>
<dt>parallel</dt>
<dd>
<p>the boolean value specified by the user regarding parallel processing.</p>
</dd>
</dl>
<h3>References</h3>

<p>Betancourt M (2016).
“Identifying the optimal integration time in Hamiltonian Monte Carlo.”
<em>arXiv preprint arXiv:1601.00225</em>.<br><br> Betancourt M (2017).
“A conceptual introduction to Hamiltonian Monte Carlo.”
<em>arXiv preprint arXiv:1701.02434</em>.<br><br> Duane S, Kennedy AD, Pendleton BJ, Roweth D (1987).
“Hybrid monte carlo.”
<em>Physics letters B</em>, <b>195</b>(2), 216–222.<br><br> Hoffman MD, Gelman A, others (2014).
“The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.”
<em>J. Mach. Learn. Res.</em>, <b>15</b>(1), 1593–1623.<br><br> Nishimura A, Dunson D (2020).
“Recycling Intermediate Steps to Improve Hamiltonian Monte Carlo.”
<em>Bayesian Analysis</em>, <b>15</b>(4).
ISSN 1936-0975, <a href="https://doi.org/10.1214/19-ba1171">doi:10.1214/19-ba1171</a>, <a href="http://dx.doi.org/10.1214/19-BA1171">http://dx.doi.org/10.1214/19-BA1171</a>.<br><br> Nishimura A, Dunson DB, Lu J (2020).
“Discontinuous Hamiltonian Monte Carlo for discrete parameters and discontinuous likelihoods.”
<em>Biometrika</em>, <b>107</b>(2), 365–380.
</p>


</div>